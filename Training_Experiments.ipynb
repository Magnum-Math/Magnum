{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Input Question\n",
      "plot x\n",
      "Would you like to print intermediate code results? yes/no\n",
      "yes\n",
      "Query Received is  plot | x\n",
      "Solution Generated\n"
     ]
    }
   ],
   "source": [
    "from app import apiWrapper\n",
    "print(\"Enter Input Question\")\n",
    "qry = input()\n",
    "qry += \" \"\n",
    "while qry.isspace():\n",
    "    qry = input(\"Enter Input Question\")\n",
    "\n",
    "print(\"Would you like to print intermediate code results? yes/no\")\n",
    "selection = input()\n",
    "while selection not in [\"yes\", \"no\"]:\n",
    "    selection = input()\n",
    "    print(\"Would you like to print intermediate code results? yes/no\")\n",
    "\n",
    "apiWrapper.getUsrQues(qry)\n",
    "RAW_TEXT, Query = apiWrapper.callApi()\n",
    "print(\"Query Received is \", Query)\n",
    "print(\"Solution Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot x\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if selection == \"yes\":\n",
    "    for line in RAW_TEXT:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from api import GPT, Example, UIConfig\n",
    "from api import demo_web_app\n",
    "from glob import glob\n",
    "def read_file(path_to_file):\n",
    "    retval = \"\"\n",
    "    file = open(path_to_file)\n",
    "    retval = file.readlines()\n",
    "    file.close()\n",
    "    #Make sure the new line character is not read it throws the model off     \n",
    "    retval = [x.split(\"/n\")[0][:-1] for x in retval]\n",
    "    return retval\n",
    "\n",
    "\n",
    "# Construct GPT object and show some examples\n",
    "gpt = GPT(engine=\"curie\",\n",
    "          temperature=0.3,\n",
    "          max_tokens=300)\n",
    "\n",
    "\n",
    "# reade file and convert it to source string and target string tuples\n",
    "source_names = [item for item in sorted(glob(\"./Training_Example/sources/*\"))]\n",
    "target_names = [item for item in sorted(glob(\"./Training_Example/latex/*\"))]\n",
    "\n",
    "\n",
    "# open each file in the Training_Example directory\n",
    "for src_path, target_path in zip(source_names,target_names):\n",
    "    \n",
    "    # For each files read the RAW and corrosponding Latex Code\n",
    "    src_RAW = read_file(src_path)\n",
    "    target_RAW = read_file(target_path)\n",
    "    \n",
    "    # for each pair of RAW and latex prime the GPT model\n",
    "    if len(src_RAW) != len(target_RAW):\n",
    "        raise Exception(\"Source and Latex have mismached number of line {} {} in file {} and {}\".format(str(len(src_RAW)), str(len(target_RAW)),src_path,target_path))\n",
    "\n",
    "    for s_RAW, t_RAW in zip(src_RAW,target_RAW):\n",
    "        gpt.add_example(Example(s_RAW,t_RAW))\n",
    "        # Uncomment the following if you would like to see the priming examples\n",
    "        #print(\"Source: \", s_RAW)\n",
    "        #print(\"Output: \", t_RAW)\n",
    "        #print(\"----\")\n",
    "        \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing Script\n",
    "\"\"\"\n",
    "testFiles = [item for item in sorted(glob(\"./Training_Example/Test/2..txt\"))]\n",
    "for file in testFiles:\n",
    "    test_RAW = read_file(file)\n",
    "    response = []\n",
    "    for line in test_RAW:\n",
    "        print(\"Prompt: \", line)\n",
    "        t = gpt.get_top_reply(line)\n",
    "        print(t,end=\"----\\n\")\n",
    "        response.append(t)\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the intermediate LateX code from OpenAI GPT3 API\n",
      "Intermediate LateX generated\n"
     ]
    }
   ],
   "source": [
    "# Converting RAW_TEXT to Latex:\n",
    "print(\"Fetching the intermediate LateX code from OpenAI GPT3 API\")\n",
    "response = []\n",
    "for line in RAW_TEXT :\n",
    "    t = gpt.get_top_reply(line)\n",
    "    response.append(t)\n",
    "print(\"Intermediate LateX generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = []\n",
    "for line in response:\n",
    "    text = line.split(\"\\n\")[0][7:]\n",
    "    if text.isspace() or text == \"\":\n",
    "        continue\n",
    "    else:\n",
    "        latex_code.append(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " plot x\n"
     ]
    }
   ],
   "source": [
    "if selection == \"yes\":\n",
    "    for line in latex_code:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Latex to Maxnim Code\n",
      "A Graph will be generated\n",
      "from manimlib.imports import *\n",
      "from math import *\n",
      "class Solution(GraphScene):\n",
      "\tCONFIG = {\n",
      "\t\t'graph_origin': ORIGIN,\n",
      "\t\t'function_color': WHITE,\n",
      "\t\t'axes_color': BLUE,\n",
      "\t\t'x_min':\t-10,\n",
      "\t\t'x_max':\t10,\n",
      "\t\t'x_labeled_nums' :range(-10,10, 2),\n",
      "\t\t'y_min':\t-10,\n",
      "\t\t'y_max':\t10,\n",
      "\t\t'y_labeled_nums' :range(-10,10,2)}\n",
      "\n",
      "\tdef construct(self):\n",
      "\t\twatermark = ImageMobject(\"./assets/water_mark.png\")\n",
      "\t\twatermark.scale(1.5)\n",
      "\t\twatermark.to_corner(DOWN+RIGHT, buff=0)\n",
      "\t\tself.play(FadeIn(watermark))\n",
      "\t\tSolve = TexMobject(r\" plot x\")\n",
      "\t\tSolve.to_edge(UP)\n",
      "\t\tself.play(Write(Solve))\n",
      "\t\tself.wait(2)\n",
      "\t\tself.play(FadeOut(Solve))\n",
      "\t\tself.setup_axes(animate=True)\n",
      "\t\tfunc_graph = self.get_graph(self.func, self.function_color)\n",
      "\t\tself.play(FadeIn(func_graph))\n",
      "\t\tself.wait(2)\n",
      "\t\t\n",
      "\tdef func(self, x):\n",
      "\t\tf = x\n",
      "\t\treturn f\n",
      "Manim Code Generated\n"
     ]
    }
   ],
   "source": [
    "from app import latex2Manim\n",
    "#import importlib\n",
    "#importlib.reload(latex2Manim)\n",
    "print(\"Converting Latex to Maxnim Code\")\n",
    "manim_code = latex2Manim.latex2Manim(latex_code,qry, \"x\")\n",
    "if selection == \"yes\":\n",
    "    print(manim_code)\n",
    "print(\"Manim Code Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manim Code saved at ./solution.py\n"
     ]
    }
   ],
   "source": [
    "fptr =  open(\"solution.py\", \"w\") \n",
    "fptr.write(manim_code)\n",
    "fptr.close()\n",
    "print(\"Manim Code saved at ./solution.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media will be written to ./Animations/. You can change this behavior with the --media_dir flag.\n",
      "                                                                                \n",
      "File ready at /home/mrselukar/manim/gpt-sandbox-cloned/Animations/videos/solution/480p15/Solution.mp4\n",
      "\n",
      "Played 7 animations\n"
     ]
    }
   ],
   "source": [
    "#!manim solution.py Solution -pl --media_dir \"./Animations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Starting to Animate\")\n",
    "retval = os.system('manim solution.py Solution -pl --media_dir \"./Animations\"')\n",
    "if retval == 0:\n",
    "    print(\"Animation Completed check ./Animations/video for output\")\n",
    "else:\n",
    "    print(\"Animation Error Check Manim Logs!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Script to find and replace spaces with \" / \" in files \n",
    "target_names = [item for item in sorted(glob(\"./Training_Example/latex/*\"))]\n",
    "retval = \"\"\n",
    "for path_to_file in target_names:\n",
    "    print(path_to_file)\n",
    "    temp = input()\n",
    "    if temp == \"yes\":\n",
    "\n",
    "        file = open(path_to_file)\n",
    "        retval = file.readlines()\n",
    "        file.close()\n",
    "        for i in range(len(retval)):\n",
    "            print(retval[i])\n",
    "            x = input()\n",
    "            if x != '0':\n",
    "                retval[i] = retval[i].replace(\" \", \" \\ \")\n",
    "        retval = [x.split(\"/n\")[0][:-1] for x in retval]\n",
    "    #print(retval)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for l in retval:\n",
    "    print (l)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x_in):\n",
    "\t\tf = lambda x : eval(x_in)\n",
    "\t\treturn f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = func('x**2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
