{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert your Math Question to Animated solution\n",
    "This is the main notebook for the Magnum Project \n",
    "The installation instructions for all the dependencies are in the readme at our [github repository](https://github.com/GPT-3-Manim/AI-Math-Animator-GPT3) \n",
    "\n",
    "### Using Custom Priming Data\n",
    "We have provided you with the basic priming data for the text to manim GPT model. \n",
    "The Latex conversion is slightly non standard as the text is interperetd in tex so to introduct spacing we have to inserte a \" / \". \n",
    "\n",
    "If you wish to provide your own examples for priming you can edit the files in the Training_Examples directoriy. \n",
    "\n",
    "### A note if you are using non standard latex packages \n",
    "We use Manim to animate the solution from wolfram follow the instructions at [manim github page](https://github.com/3b1b/manim) to get manim up and running \n",
    "\n",
    "If your latex code uses non-standard or additional packages you will need the manim source code and not the pip version \n",
    "\n",
    "Again the instructions to install the required version are given on [manim github page](https://github.com/3b1b/manim) or you can follow [the manim docs here](https://readthedocs.org/projects/manim/downloads/pdf/latest/)\n",
    "\n",
    "For non standard latex packages follow [this amazing video](https://www.youtube.com/watch?v=VPYmZWTjHoU)\n",
    "\n",
    "### Rendering options \n",
    "Manim provides you with a full array of rendering options from setting aspect ratios to resoultion and framerate. \n",
    "\n",
    "Follow the [video here to get insight on all the options](https://www.youtube.com/watch?v=d_2V5mC2hx0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mrselukar/manim/gpt-sandbox-cloned\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os \n",
    "from pathlib import Path\n",
    "data_folder = Path(os.getcwd())\n",
    "openai.api_key = open(data_folder / 'api_keys/openai').readline().rstrip('\\n')\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Input Question\n",
      "x-7=0\n",
      "Would you like to print intermediate code results? yes/no\n",
      "yes\n",
      "Query Received is  x - 7 = 0\n",
      "Solution Generated\n"
     ]
    }
   ],
   "source": [
    "from app import apiWrapper\n",
    "print(\"Enter Input Question\")\n",
    "qry = input()\n",
    "qry += \" \"\n",
    "while qry.isspace():\n",
    "    qry = input(\"Enter Input Question\")\n",
    "\n",
    "print(\"Would you like to print intermediate code results? yes/no\")\n",
    "selection = input()\n",
    "while selection not in [\"yes\", \"no\"]:\n",
    "    selection = input()\n",
    "    print(\"Would you like to print intermediate code results? yes/no\")\n",
    "\n",
    "apiWrapper.getUsrQues(qry)\n",
    "RAW_TEXT, Query = apiWrapper.callApi()\n",
    "Query = Query.replace(\"|\",\"\")\n",
    "print(\"Query Received is \", Query)\n",
    "print(\"Solution Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve for x:\n",
      "x - 7 = 0\n",
      "Add 7 to both sides:\n",
      "x + (7 - 7) = 7\n",
      "7 - 7 = 0:\n",
      "Answer:  x = 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if selection == \"yes\":\n",
    "    for line in RAW_TEXT:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from api import GPT, Example\n",
    "from glob import glob\n",
    "def read_file(path_to_file):\n",
    "    retval = \"\"\n",
    "    file = open(path_to_file)\n",
    "    retval = file.readlines()\n",
    "    file.close()\n",
    "    #Make sure the new line character is not read it throws the model off     \n",
    "    retval = [x.split(\"/n\")[0][:-1] for x in retval]\n",
    "    return retval\n",
    "\n",
    "\n",
    "# Construct GPT object and show some examples\n",
    "gpt = GPT(engine=\"davinci\",\n",
    "          temperature=0.01,\n",
    "          max_tokens=150)\n",
    "\n",
    "\n",
    "# reade file and convert it to source string and target string tuples\n",
    "source_names = [item for item in sorted(glob(str(data_folder / \"Training_Example/text2latex/sources/*\")))]\n",
    "target_names = [item for item in sorted(glob( str(data_folder / \"Training_Example/text2latex/latex/*\")))]\n",
    "\n",
    "\n",
    "# open each file in the Training_Example directory\n",
    "for src_path, target_path in zip(source_names,target_names):\n",
    "    \n",
    "    # For each files read the RAW and corrosponding Latex Code\n",
    "    src_RAW = read_file(src_path)\n",
    "    target_RAW = read_file(target_path)\n",
    "    \n",
    "    # for each pair of RAW and latex prime the GPT model\n",
    "    if len(src_RAW) != len(target_RAW):\n",
    "        raise Exception(\"Source and Latex have mismached number of line {} {} in file {} and {}\".format(str(len(src_RAW)), str(len(target_RAW)),src_path,target_path))\n",
    "\n",
    "    for s_RAW, t_RAW in zip(src_RAW,target_RAW):\n",
    "        gpt.add_example(Example(s_RAW,t_RAW))\n",
    "        # Uncomment the following if you would like to see the priming examples\n",
    "        #print(\"Source: \", s_RAW)\n",
    "        #print(\"Output: \", t_RAW)\n",
    "        #print(\"----\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct GPT object and show some examples\n",
    "gpt_py = GPT(engine=\"davinci\",\n",
    "          temperature=0.01,\n",
    "          max_tokens=100)\n",
    "\n",
    "\n",
    "# reade file and convert it to source string and target string tuples\n",
    "source_names = [item for item in sorted(glob( str(data_folder / \"Training_Example/text2py/sources/*\")))]\n",
    "target_names = [item for item in sorted(glob( str(data_folder / \"Training_Example/text2py/python/*\")))]\n",
    "\n",
    "\n",
    "# open each file in the Training_Example directory\n",
    "for src_path, target_path in zip(source_names,target_names):\n",
    "    \n",
    "    # For each files read the RAW and corrosponding Latex Code\n",
    "    src_RAW = read_file(src_path)\n",
    "    target_RAW = read_file(target_path)\n",
    "    \n",
    "    # for each pair of RAW and latex prime the GPT model\n",
    "    if len(src_RAW) != len(target_RAW):\n",
    "        raise Exception(\"Source and Latex have mismached number of line {} {} in file {} and {}\".format(str(len(src_RAW)), str(len(target_RAW)),src_path,target_path))\n",
    "\n",
    "    for s_RAW, t_RAW in zip(src_RAW,target_RAW):\n",
    "        gpt_py.add_example(Example(s_RAW,t_RAW))\n",
    "        # Uncomment the following if you would like to see the priming examples\n",
    "        #print(\"Source: \", s_RAW)\n",
    "        #print(\"Output: \", t_RAW)\n",
    "        #print(\"----\")\n",
    "        \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to convert input query to graphable python function\n",
      "Interpereted python function is  x - 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting RAW_TEXT Query to Python Function:\n",
    "print(\"Attempting to convert input query to graphable python function\")\n",
    "python_func = gpt_py.get_top_reply(Query)\n",
    "python_func = python_func[7:]\n",
    "python_func = python_func.split(\"/n\")[0]\n",
    "print(\"Interpereted python function is\", python_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the intermediate LateX code from OpenAI GPT3 API\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4738c0230b4565a1dfd42571b7edd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting RAW_TEXT to Latex:\n",
    "from tqdm.auto import tqdm\n",
    "print(\"Fetching the intermediate LateX code from OpenAI GPT3 API\")\n",
    "response = []\n",
    "for i in tqdm(range(len(RAW_TEXT))) :\n",
    "    line = RAW_TEXT[i]\n",
    "    t = gpt.get_top_reply(line)\n",
    "    response.append(t)\n",
    "print(\"Intermediate LateX generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = []\n",
    "for line in response:\n",
    "    text = line.split(\"\\n\")[0][7:]\n",
    "    if text.isspace() or text == \"\":\n",
    "        continue\n",
    "    else:\n",
    "        latex_code.append(text +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./latex.txt','w')\n",
    "for i in range(len(latex_code)):\n",
    "    f.write(latex_code[i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selection == \"yes\":\n",
    "    for line in latex_code:\n",
    "        print(line, end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_func = python_func.split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from app import latex2Manim\n",
    "import importlib\n",
    "importlib.reload(latex2Manim)\n",
    "print(\"Converting Latex to Maxnim Code\")\n",
    "manim_code = latex2Manim.latex2Manim(latex_code, python_func ,python_func)\n",
    "if selection == \"yes\":\n",
    "    print(manim_code)\n",
    "print(\"Manim Code Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fptr =  open(data_folder / \"solution.py\", \"w\") \n",
    "fptr.write(manim_code)\n",
    "fptr.close()\n",
    "print(\"Manim Code saved at {}/solution.py\".format(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are rendering inside the notebook use the cell below\n",
    "#!manim solution.py Solution -pl --media_dir \"./Animations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make the magnum.py file\n",
    "\"\"\"\n",
    "import os\n",
    "print(\"Starting to Animate. Arguments for manim if any?\")\n",
    "args = input()\n",
    "retval = os.system('manim ' + str(data_folder) + '/solution.py Solution ' + args +' --media_dir ' + str(data_folder) +'\"/Animations\"')\n",
    "if retval == 0:\n",
    "    print(\"Animation Completed check ./Animations/video for output\")\n",
    "else:\n",
    "    print(\"Animation Error Check Manim Logs!!\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "titlepage": {
   "author": "Mayur Selukar",
   "email": "mayur.selukar1@gmail.com",
   "linkedin": "https://www.linkedin.com/in/mayur-selukar/",
   "tagline": "Convert Latex code to beautiful animations",
   "title": "Latex2manim",
   "website": "https://mrselukar.github.io/"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
